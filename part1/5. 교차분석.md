### numerical과 categorical 데이터  
numerical : 숫자 자체가 의미를 갖는 데이터  
예) 신장, 몸무게 등  
categorical : 숫자는 종류를 분류하는 용도로만 사용되는 데이터  
예) 남자는 1, 여자는 2로 나타낸 성별 데이터 등  

### 교차분석
구현은 pandas의 .crosstab()을 활용해 구현이 가능하다. (코드 생략)  

### 통계 검정과 Chi-square
사람의 신장 값들과 사람들이 연간 구매한 바디워시의 갯수를 축으로 하는 데이터가 있다고 해보자.  
두 변인이 통계학적으로 서로 영향이 있는지를 확인하는 과정을 통계 검정이라고 한다.  
우리는 그중에서도 Chi-square 검정, 혹은 카이제곱 검정을 알아보자.  
카이제곱 검정이란 통해 두 범주형 변수 사이에 관계가 있는지 없는지를 검정하는 통계검정 방식으로, 독립성 검정이다. (두 변인이 독립적인지 확인)  

우선 주어진 데이터로부터 귀무가설과 대립가설이 설정된다.  
귀무가설(Null hypothesis): 신장에 따라 바디워시 구매량에 차이가 없다 (independent, 독립적이다)  
대립가설: 신장에 따라 바디워시 구매량에 차이가 있다 (dependent, 독립적이지 않다)  

구현  
```python
stats.chisquare(df['height'], df['bodywash_bought'])

# Output
# Power_divergenceResult(statistic=xxxx.xxxxxx, pvalue=x.xxxxxxx)
# 만약 pvalue가 0.05이하라면 이는 두 변인에 유의미한 상관관계가 있음을 의미한다. 0.05라는 수치는 임의로 정해둔 수치로, 더 엄밀한 검정이 필요하면 pvalue값 커트를 0.01과 같이 더 낮출 수도 있다
```  

pvalue를 아주 간략하게 설명하면, pvalue란 관찰 데이터의 통계량이 귀무가설을 지지하는 정도를 의미한다. 즉 pvalue가 0.05라면 5% 지지한다는 의미이다.  
이는 반대로 말해 5% 귀무가설이 참일 가능성도 있다는 말이기에 pvalue가 절대적인 것은 아니다.  
